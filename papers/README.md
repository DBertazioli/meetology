<div align = "center">
<h1>Paper description</h1>
</div>
Papers description follow
<br>
<br>
<div align = "center">
<h3>Ontology</h3>
</div>

- Stuart J. Chalk, (2016). <strong>"SciData: a data model and ontology for semantic representation of scientific data"</strong>, Journal of Cheminformatics, 8 (1), 1.


<p>Article about the use of JSON-LD in creating an ontology for scientific data, in particular chemistry.</p>
<br>
<br>
<br>
<div align = "center">
<h3>Description categories</h3>
</div>

- Alper Kursat Uysal and Serkan Gunal, (2014). <strong>"The impact of preprocessing on text classification"</strong>, Information Processing & Management, 50 (1), 104-112, ISSN 0306-4573.
<p>Paper about the influence of widely used preprocessing tasks on text classification examined in two different domains and languages.</p>
<br>

- D. Xue and F. Li, (2015). <strong>"Research of Text Categorization Model based on Random Forests"</strong>,  2015 IEEE International Conference on Computational Intelligence & Communication Technology, Ghaziabad, 173-176.
<p>This paper first introduced random forests then establish a text categorization model based on random forest and design the experiment to evaluate its performance.</p>
<br>

- David M. Blei, Andrew Y. Ng, Michael I. Jordan, (2003). <strong>"Latent dirichlet allocation"</strong>, The Journal of Machine Learning Research, 3, 993-1022. 
<p>Simplified explanations for this argument are available <a href = "http://www.andreaminini.com/semantica/latent-dirichlet-allocation-lda#come_funziona_l'allocazione_lda">here</a> and <a href = "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158">here</a>. This paper describe latent Dirichlet allocation, a flexible generative probabilistic model for collections of discrete data, based on a simple exchangeability assumption for the words and topics in a document.</p>
<br>

-  Le Q. and Mikolov T. , (2014). <strong>"Distributed Representations of Sentences and Documents"</strong>, Proceedings of the 31st International Conference on Machine Learning, in PMLR, 32(2), 1188-1196.
<p>This paper is about Paragraph Vector (future doc2vec), an unsupervised learning algorithm that learns vector representations for variable-length pieces of texts such as sentences and documents. The vector representations are learned to predict the surrounding words in contexts sampled from the paragraph.</p>
