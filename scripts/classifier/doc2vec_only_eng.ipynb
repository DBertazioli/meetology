{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#warnings.filterwarnings(action='once')\n",
    "#!pip install tqdm #--user\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "#!pip install gensim #--user\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The english-only version of the doc2vec model (increased performances!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_df=pd.read_csv(\"meetup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_df=supp_df[supp_df[\"category\"].isna()!=True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBT',\n",
       " 'alternative lifestyle',\n",
       " 'book clubs',\n",
       " 'career business',\n",
       " 'cars motorcycles',\n",
       " 'community environment',\n",
       " 'dancing',\n",
       " 'education learning',\n",
       " 'fashion beauty',\n",
       " 'fine arts culture',\n",
       " 'fitness',\n",
       " 'food drink',\n",
       " 'games',\n",
       " 'health wellbeing',\n",
       " 'hobbies crafts',\n",
       " 'language ethnic identity',\n",
       " 'movements politics',\n",
       " 'movies film',\n",
       " 'music',\n",
       " 'new age spirituality',\n",
       " 'outdoors adventure',\n",
       " 'paranormal',\n",
       " 'parents family',\n",
       " 'pets animals',\n",
       " 'photography',\n",
       " 'religion beliefs',\n",
       " 'sci-fi fantasy',\n",
       " 'singles',\n",
       " 'socializing',\n",
       " 'sports recreation',\n",
       " 'support',\n",
       " 'tech',\n",
       " 'writing']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_list=list(supp_df.category.unique())\n",
    "cat_list=[str(elem) for elem in cat_list]\n",
    "cat_list.sort()\n",
    "cat_list=[elem.replace(\"/\", \" \") for elem in cat_list]\n",
    "\"\"\"\n",
    "cat_list_old= cat_list[:]\n",
    "cat_list=[]\n",
    "for elem in cat_list_old:\n",
    "    if \" \" in elem:\n",
    "        els=elem.split(\" \")\n",
    "        cat_list.append(els)\n",
    "    else:\n",
    "        cat_list.append(elem)\n",
    "\"\"\"\n",
    "cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>category_bin</th>\n",
       "      <th>lang_ok</th>\n",
       "      <th>processed_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;FOOD AND FELLOWSHIP | 5 PM&lt;/p&gt; \\n&lt;p&gt;CONCERT...</td>\n",
       "      <td>27</td>\n",
       "      <td>english</td>\n",
       "      <td>food fellowship concert may us morn star churc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;【WhyNot!?JAPAN + MeetUp Collaboration Ev...</td>\n",
       "      <td>28</td>\n",
       "      <td>english</td>\n",
       "      <td>whynot japan collabor peopl come whynot japan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;TENTATIVE&lt;br&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;br&gt;&lt;/p&gt;\\n&lt;p&gt;10.30 - ...</td>\n",
       "      <td>31</td>\n",
       "      <td>english</td>\n",
       "      <td>tent introduct orient session break network au...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  <p>FOOD AND FELLOWSHIP | 5 PM</p> \\n<p>CONCERT...   \n",
       "1           1  <p><b>【WhyNot!?JAPAN + MeetUp Collaboration Ev...   \n",
       "2           2  <p>TENTATIVE<br></p>\\n<p><br></p>\\n<p>10.30 - ...   \n",
       "\n",
       "   category_bin  lang_ok                              processed_description  \n",
       "0            27  english  food fellowship concert may us morn star churc...  \n",
       "1            28  english  whynot japan collabor peopl come whynot japan ...  \n",
       "2            31  english  tent introduct orient session break network au...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"processed_description_sine_error_Porter_no_bad_words.csv\")\n",
    "df=df[df[\"lang_ok\"]==\"english\"]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>category_bin</th>\n",
       "      <th>lang_ok</th>\n",
       "      <th>processed_description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;FOOD AND FELLOWSHIP | 5 PM&lt;/p&gt; \\n&lt;p&gt;CONCERT...</td>\n",
       "      <td>27</td>\n",
       "      <td>english</td>\n",
       "      <td>food fellowship concert may us morn star churc...</td>\n",
       "      <td>singles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;【WhyNot!?JAPAN + MeetUp Collaboration Ev...</td>\n",
       "      <td>28</td>\n",
       "      <td>english</td>\n",
       "      <td>whynot japan collabor peopl come whynot japan ...</td>\n",
       "      <td>socializing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  <p>FOOD AND FELLOWSHIP | 5 PM</p> \\n<p>CONCERT...   \n",
       "1           1  <p><b>【WhyNot!?JAPAN + MeetUp Collaboration Ev...   \n",
       "\n",
       "   category_bin  lang_ok                              processed_description  \\\n",
       "0            27  english  food fellowship concert may us morn star churc...   \n",
       "1            28  english  whynot japan collabor peopl come whynot japan ...   \n",
       "\n",
       "      category  \n",
       "0      singles  \n",
       "1  socializing  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"]=\"NaN\"\n",
    "\n",
    "df[\"category\"]= df.apply(lambda r: cat_list[r.category_bin], axis=1)\n",
    "del supp_df\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_all=True\n",
    "#process_all=True\n",
    "\n",
    "if process_all:\n",
    "    train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "else:    \n",
    "    train, test = train_test_split(df[:50000], test_size=0.3, random_state=42)\n",
    "\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=str(r.processed_description).split(\" \"), tags=[r.category]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=str(r.processed_description).split(\" \"), tags=[r.category]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_tagged.values[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "#cores = multiprocessing.cpu_count()\n",
    "#cores\n",
    "cores=4\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114181/114181 [00:00<00:00, 3951596.82it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114181/114181 [00:00<00:00, 4902844.24it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 2822412.79it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3597877.12it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 2503972.73it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3053025.71it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3544460.83it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3643645.43it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3229853.95it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3574994.40it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3531106.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 38s, sys: 6.14 s, total: 6min 45s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(10):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    #sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in tqdm(tagged_docs.values)])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114181/114181 [08:14<00:00, 231.04it/s]\n",
      "100%|██████████| 48935/48935 [03:20<00:00, 244.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 35s, sys: 1.14 s, total: 11min 36s\n",
      "Wall time: 11min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go=False\n",
    "go=True\n",
    "if go:\n",
    "    import joblib\n",
    "    joblib.dump(model_dbow, \"model_dbow_all_only_eng_10_ep_Porter_no_bad_words.joblib\")\n",
    "    process_all=False\n",
    "    if process_all:\n",
    "        joblib.dump(X_train, \"X_train_all_10_ep_Porter_no_bad_words.joblib\")\n",
    "        joblib.dump(y_train, \"y_train_all_10_ep_Porter_no_bad_words.joblib\")\n",
    "        joblib.dump(X_test, \"X_test_all_10_ep_Porter_no_bad_words.joblib\")\n",
    "        joblib.dump(y_test, \"y_test_all_10_ep_Porter_no_bad_words.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.6514178541577478\n",
      "Testing F1 score: 0.6497767054978865\n"
     ]
    }
   ],
   "source": [
    "go=False\n",
    "#go=True\n",
    "\n",
    "if go:\n",
    "    logreg = LogisticRegression(n_jobs=5, C=1e5, solver=\"sag\")\n",
    "\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "    print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "    print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114181/114181 [00:00<00:00, 2170932.25it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114181/114181 [00:00<00:00, 2916891.46it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3680015.25it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3525803.03it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3186635.07it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 1819034.04it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3558392.59it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 2217883.61it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 3037784.89it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 2687153.24it/s]\n",
      "100%|██████████| 114181/114181 [00:00<00:00, 2937268.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 46s, sys: 13.6 s, total: 9min 59s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(10):\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114181/114181 [11:07<00:00, 171.04it/s]\n",
      "100%|██████████| 48935/48935 [04:53<00:00, 166.94it/s]\n"
     ]
    }
   ],
   "source": [
    "y_train_dmm, X_train_dmm = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test_dmm, X_test_dmm = vec_for_learning(model_dmm, test_tagged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "go=True\n",
    "#go=True\n",
    "if go:\n",
    "    import joblib\n",
    "    joblib.dump(model_dmm, \"model_ddm_all_only_eng_10_ep_Porter_no_badwords.joblib\")\n",
    "    process_all=False\n",
    "    if process_all:\n",
    "        joblib.dump(X_train_dmm, \"X_train_all_ddm_10_ep_Porter_no_badwords.joblib\")\n",
    "        joblib.dump(y_train_dmm, \"y_train_all_ddm_10_ep_Porter_no_badwords.joblib\")\n",
    "        joblib.dump(X_test_dmm, \"X_test_all_ddm_10_ep_Porter_no_badwords.joblib\")\n",
    "        joblib.dump(y_test_dmm, \"y_test_all_ddm_10_ep_Porter_no_badwords.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114181/114181 [19:40<00:00, 96.73it/s] \n",
      "100%|██████████| 48935/48935 [08:37<00:00, 94.60it/s] \n"
     ]
    }
   ],
   "source": [
    "y_train_pair, X_train_pair = vec_for_learning(new_model, train_tagged)\n",
    "y_test_pair, X_test_pair = vec_for_learning(new_model, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "go=True\n",
    "if go:\n",
    "    import joblib\n",
    "    joblib.dump(new_model, \"model_pair_all_only_eng_10_ep_Porter_no_badwords.joblib\")\n",
    "    process_all=False\n",
    "    if process_all:\n",
    "        joblib.dump(X_train_pair, \"X_train_all_pair_10_ep_Porter_no_badwords.joblib\")\n",
    "        joblib.dump(y_train_pair, \"y_train_all_pair_10_ep_Porter_no_badwords.joblib\")\n",
    "        joblib.dump(X_test_pair, \"X_test_all_pair_10_ep_Porter_no_badwords.joblib\")\n",
    "        joblib.dump(y_test_pair, \"y_test_all_pair_10_ep_Porter_no_badwords.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_jobs=4, n_estimators=100) \n",
    "forest = forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save=True\n",
    "if save:\n",
    "    import joblib\n",
    "    joblib.dump(forest, \"model_rf_only_eng_dbow_72acc.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7247573311535711\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                    LGBT       0.99      0.35      0.52       463\n",
      "   alternative lifestyle       0.97      0.78      0.86       223\n",
      "              book clubs       0.68      0.45      0.54       388\n",
      "         career business       0.70      0.83      0.76      4580\n",
      "        cars motorcycles       0.98      0.50      0.66       362\n",
      "   community environment       0.82      0.46      0.59       944\n",
      "                 dancing       0.82      0.81      0.82      1090\n",
      "      education learning       0.79      0.48      0.60      1003\n",
      "          fashion beauty       0.71      0.40      0.51        81\n",
      "       fine arts culture       0.82      0.60      0.69      1027\n",
      "                 fitness       0.79      0.69      0.74      2269\n",
      "              food drink       0.75      0.56      0.64      1424\n",
      "                   games       0.85      0.82      0.83      1469\n",
      "        health wellbeing       0.71      0.81      0.75      4532\n",
      "          hobbies crafts       0.80      0.60      0.68       515\n",
      "language ethnic identity       0.82      0.66      0.73      1773\n",
      "      movements politics       0.83      0.78      0.80       752\n",
      "             movies film       0.75      0.45      0.56       539\n",
      "                   music       0.79      0.61      0.69       895\n",
      "    new age spirituality       0.78      0.74      0.76      3001\n",
      "      outdoors adventure       0.74      0.86      0.79      5385\n",
      "              paranormal       0.60      0.13      0.21        23\n",
      "          parents family       0.89      0.50      0.64       640\n",
      "            pets animals       0.92      0.45      0.61       312\n",
      "             photography       0.95      0.76      0.84       584\n",
      "        religion beliefs       0.84      0.49      0.62       777\n",
      "          sci-fi fantasy       0.86      0.32      0.47       287\n",
      "                 singles       0.61      0.32      0.42       844\n",
      "             socializing       0.47      0.73      0.57      5125\n",
      "       sports recreation       0.84      0.83      0.84      2470\n",
      "                 support       0.93      0.38      0.54       431\n",
      "                    tech       0.82      0.87      0.84      4340\n",
      "                 writing       0.90      0.65      0.76       387\n",
      "\n",
      "                accuracy                           0.72     48935\n",
      "               macro avg       0.80      0.60      0.66     48935\n",
      "            weighted avg       0.75      0.72      0.72     48935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(forest.score(X_test, y_test))\n",
    "\n",
    "predictions = forest.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predictions)) #100 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest1 = RandomForestClassifier(n_jobs=6, n_estimators=200) \n",
    "forest1 = forest.fit(X_train_dmm, y_train_dmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5346071319096761"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest1.score(X_test_dmm, y_test_dmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save=True\n",
    "if save:\n",
    "    joblib.dump(forest1, \"model_rf_only_eng_dmm.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                    LGBT       1.00      0.14      0.25       463\n",
      "   alternative lifestyle       0.66      0.67      0.67       223\n",
      "              book clubs       0.96      0.11      0.20       388\n",
      "         career business       0.46      0.75      0.57      4580\n",
      "        cars motorcycles       0.98      0.17      0.29       362\n",
      "   community environment       0.94      0.17      0.29       944\n",
      "                 dancing       0.86      0.44      0.58      1090\n",
      "      education learning       0.84      0.25      0.38      1003\n",
      "          fashion beauty       0.73      0.14      0.23        81\n",
      "       fine arts culture       0.92      0.29      0.44      1027\n",
      "                 fitness       0.68      0.44      0.53      2269\n",
      "              food drink       0.82      0.25      0.38      1424\n",
      "                   games       0.92      0.37      0.53      1469\n",
      "        health wellbeing       0.47      0.70      0.56      4532\n",
      "          hobbies crafts       0.95      0.17      0.29       515\n",
      "language ethnic identity       0.83      0.38      0.52      1773\n",
      "      movements politics       0.97      0.45      0.61       752\n",
      "             movies film       0.87      0.16      0.27       539\n",
      "                   music       0.92      0.24      0.38       895\n",
      "    new age spirituality       0.66      0.51      0.57      3001\n",
      "      outdoors adventure       0.55      0.79      0.65      5385\n",
      "              paranormal       0.00      0.00      0.00        23\n",
      "          parents family       0.93      0.16      0.27       640\n",
      "            pets animals       0.98      0.15      0.26       312\n",
      "             photography       0.99      0.38      0.54       584\n",
      "        religion beliefs       0.94      0.15      0.26       777\n",
      "          sci-fi fantasy       0.95      0.07      0.13       287\n",
      "                 singles       0.60      0.15      0.24       844\n",
      "             socializing       0.32      0.63      0.43      5125\n",
      "       sports recreation       0.76      0.65      0.70      2470\n",
      "                 support       0.94      0.17      0.29       431\n",
      "                    tech       0.57      0.77      0.65      4340\n",
      "                 writing       0.99      0.26      0.41       387\n",
      "\n",
      "                accuracy                           0.53     48935\n",
      "               macro avg       0.79      0.34      0.41     48935\n",
      "            weighted avg       0.65      0.53      0.51     48935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = forest1.predict(X_test_dmm)\n",
    "print(metrics.classification_report(y_test_dmm, predictions)) #100 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pair = RandomForestClassifier(n_jobs=6) \n",
    "forest_pair = forest.fit(X_train_pair, y_train_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7161949524879943"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_pair.score(X_test_pair, y_test_pair)#100feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "save=True\n",
    "if save:\n",
    "    joblib.dump(forest_pair, \"model_rf_pair_only_eng.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                    LGBT       0.99      0.33      0.49       463\n",
      "   alternative lifestyle       0.97      0.75      0.85       223\n",
      "              book clubs       0.71      0.44      0.54       388\n",
      "         career business       0.68      0.84      0.75      4580\n",
      "        cars motorcycles       0.98      0.46      0.63       362\n",
      "   community environment       0.83      0.45      0.58       944\n",
      "                 dancing       0.82      0.80      0.81      1090\n",
      "      education learning       0.80      0.46      0.59      1003\n",
      "          fashion beauty       0.76      0.31      0.44        81\n",
      "       fine arts culture       0.82      0.59      0.68      1027\n",
      "                 fitness       0.80      0.69      0.74      2269\n",
      "              food drink       0.75      0.55      0.63      1424\n",
      "                   games       0.85      0.80      0.82      1469\n",
      "        health wellbeing       0.70      0.80      0.75      4532\n",
      "          hobbies crafts       0.80      0.59      0.68       515\n",
      "language ethnic identity       0.82      0.65      0.72      1773\n",
      "      movements politics       0.85      0.77      0.81       752\n",
      "             movies film       0.75      0.43      0.55       539\n",
      "                   music       0.79      0.60      0.68       895\n",
      "    new age spirituality       0.77      0.73      0.75      3001\n",
      "      outdoors adventure       0.73      0.86      0.79      5385\n",
      "              paranormal       0.75      0.13      0.22        23\n",
      "          parents family       0.91      0.48      0.63       640\n",
      "            pets animals       0.95      0.41      0.58       312\n",
      "             photography       0.94      0.74      0.83       584\n",
      "        religion beliefs       0.83      0.46      0.59       777\n",
      "          sci-fi fantasy       0.93      0.29      0.44       287\n",
      "                 singles       0.59      0.30      0.40       844\n",
      "             socializing       0.45      0.72      0.56      5125\n",
      "       sports recreation       0.84      0.83      0.83      2470\n",
      "                 support       0.93      0.35      0.51       431\n",
      "                    tech       0.81      0.86      0.84      4340\n",
      "                 writing       0.92      0.63      0.75       387\n",
      "\n",
      "                accuracy                           0.72     48935\n",
      "               macro avg       0.81      0.58      0.65     48935\n",
      "            weighted avg       0.75      0.72      0.71     48935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = forest_pair.predict(X_test_pair)\n",
    "print(metrics.classification_report(y_test_pair, predictions)) #100 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
